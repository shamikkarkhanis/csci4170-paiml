{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bf245e",
   "metadata": {},
   "source": [
    "# Homework 2: Hw1 but with decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f973c2",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4790e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub==0.4.1 in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
      "Requirement already satisfied: kagglesdk<1.0,>=0.1.14 in /usr/local/lib/python3.12/dist-packages (from kagglehub==0.4.1) (0.1.15)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub==0.4.1) (25.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub==0.4.1) (6.0.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub==0.4.1) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub==0.4.1) (4.67.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kagglesdk<1.0,>=0.1.14->kagglehub==0.4.1) (5.29.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub==0.4.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub==0.4.1) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub==0.4.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub==0.4.1) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "!pip install kagglehub==0.4.1\n",
    "import kagglehub\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e878098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'creditcardfraud' dataset.\n"
     ]
    }
   ],
   "source": [
    "# Data at https://www.kaggle.com/datasets/mlg-ulb/creditcardataraud/data\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "data = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d5053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9909e673-8ff4-4b62-8ed9-ef1a75620b3f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9909e673-8ff4-4b62-8ed9-ef1a75620b3f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-9909e673-8ff4-4b62-8ed9-ef1a75620b3f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-9909e673-8ff4-4b62-8ed9-ef1a75620b3f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ecdb1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "# raw class distribution\n",
    "print('No Frauds', round(data['Class'].value_counts()[0] / len(data) * 100, 2), '% of the dataset')\n",
    "print('Frauds', round(data['Class'].value_counts()[1] / len(data) * 100, 2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62da12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature        VIF\n",
      "0     Time   1.879918\n",
      "1       V1   1.669207\n",
      "2       V2   4.449598\n",
      "3       V3   1.949665\n",
      "4       V4   1.172672\n",
      "5       V5   2.871870\n",
      "6       V6   1.577457\n",
      "7       V7   3.015964\n",
      "8       V8   1.132849\n",
      "9       V9   1.043109\n",
      "10     V10   1.220611\n",
      "11     V11   1.164665\n",
      "12     V12   1.170906\n",
      "13     V13   1.008529\n",
      "14     V14   1.225672\n",
      "15     V15   1.063474\n",
      "16     V16   1.081010\n",
      "17     V17   1.234457\n",
      "18     V18   1.057536\n",
      "19     V19   1.042558\n",
      "20     V20   2.399238\n",
      "21     V21   1.143026\n",
      "22     V22   1.089140\n",
      "23     V23   1.158154\n",
      "24     V24   1.000924\n",
      "25     V25   1.130838\n",
      "26     V26   1.003399\n",
      "27     V27   1.010661\n",
      "28     V28   1.001605\n",
      "29  Amount  12.120566\n",
      "30   Class   2.090472\n"
     ]
    }
   ],
   "source": [
    "# A fast vif as compared to previous statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "def fast_vif(df):\n",
    "    corr = df.corr().values\n",
    "    vif = np.diag(np.linalg.inv(corr))\n",
    "    return pd.DataFrame({'feature': df.columns, 'VIF': vif})\n",
    "\n",
    "vif_df = fast_vif(data)\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01c5d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          feature       VIF\n",
      "0            Time  1.880363\n",
      "1              V1  1.061633\n",
      "2              V2  1.351535\n",
      "3              V3  1.413387\n",
      "4              V4  1.057818\n",
      "5              V5  1.206235\n",
      "6              V6  1.055028\n",
      "7              V7  1.102116\n",
      "8              V8  1.004131\n",
      "9              V9  1.030772\n",
      "10            V10  1.100042\n",
      "11            V11  1.169442\n",
      "12            V12  1.170708\n",
      "13            V13  1.008239\n",
      "14            V14  1.211118\n",
      "15            V15  1.071314\n",
      "16            V16  1.096964\n",
      "17            V17  1.233806\n",
      "18            V18  1.044434\n",
      "19            V19  1.004530\n",
      "20            V20  1.039650\n",
      "21            V21  1.019136\n",
      "22            V22  1.042707\n",
      "23            V23  1.006304\n",
      "24            V24  1.001013\n",
      "25            V25  1.102228\n",
      "26            V26  1.003672\n",
      "27            V27  1.003934\n",
      "28            V28  1.000361\n",
      "29          Class  2.089810\n",
      "30  Scaled_Amount  1.644080\n"
     ]
    }
   ],
   "source": [
    "# scaling amount coloumn to make vars less corrolated | Amount = 11.50 !!\n",
    "data['Log_Amount'] = np.log1p(data['Amount'])\n",
    "scaler = StandardScaler()\n",
    "data['Scaled_Amount'] = scaler.fit_transform(data['Log_Amount'].values.reshape(-1,1))\n",
    "scaled_data = data.drop(['Amount','Log_Amount'], axis=1)\n",
    "\n",
    "# check correlation\n",
    "scaled_data_vif = fast_vif(scaled_data)\n",
    "print(scaled_data_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b79838eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up data splits\n",
    "X = scaled_data.drop(['Class', 'Time'], axis = 1)\n",
    "y = scaled_data['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7aa86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7650750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and evaluate with decision tree\n",
    "tree = DecisionTreeClassifier(random_state = 42, class_weight = 'balanced')\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2cb1b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9991573329588147\n",
      "F1 Score: 0.75\n",
      "Confusion Matrix: [[56842    22]\n",
      " [   26    72]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.77      0.73      0.75        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.88      0.87      0.87     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reporting of results\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix: {confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report: {classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea48e93",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "- low max depth: causes model to lean to biases as more data is left at the leafs. A few high level splits allow us to focus on the most important, differentiable features but does not get specific enough. \n",
    "- high max depth: leads to a model with small amounts of data in the leafs leading to overfitting. this is a high variance model with many leaf nodes. \n",
    "- min samples leaf: this prunes the model and prevents branches with not enough data in the leaf. this allows the model to generalize better. the tree will vary with deep and shallow branches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2cc55f",
   "metadata": {},
   "source": [
    "### Sensity Analysis\n",
    "- identifies which variables drive the most change, in a decision tree these are the specific thresholds used for partitions. \n",
    "- performed selecting an achor point and wiggling the range of values for the top features of your data. we then run the edited model for each and compare the results. \n",
    "- we can use sklearn to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7c76443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V14: 0.0014\n",
      "V12: 0.0013\n",
      "V7: 0.0009\n",
      "V3: 0.0008\n",
      "V4: 0.0005\n",
      "V11: 0.0005\n",
      "V15: 0.0004\n",
      "V1: 0.0003\n",
      "V18: 0.0002\n",
      "V26: 0.0001\n",
      "V27: 0.0001\n",
      "V21: 0.0001\n",
      "V10: 0.0001\n",
      "V5: 0.0001\n",
      "V8: 0.0001\n",
      "Scaled_Amount: 0.0001\n",
      "V9: 0.0001\n",
      "V16: 0.0000\n",
      "V25: 0.0000\n",
      "V13: 0.0000\n",
      "V23: 0.0000\n",
      "V20: 0.0000\n",
      "V24: 0.0000\n",
      "V22: 0.0000\n",
      "V28: 0.0000\n",
      "V2: -0.0000\n",
      "V6: -0.0000\n",
      "V19: -0.0000\n",
      "V17: -0.0000\n"
     ]
    }
   ],
   "source": [
    "result = permutation_importance(tree, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "for i in result.importances_mean.argsort()[::-1]:\n",
    "    print(f\"{X_test.columns[i]}: {result.importances_mean[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36483a1",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f6e545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 5 | Mean Accuracy: 0.9996 (+/- 0.0001)\n",
      "K=10 | Mean Accuracy: 0.9996 (+/- 0.0000)\n",
      "K=15 | Mean Accuracy: 0.9996 (+/- 0.0001)\n"
     ]
    }
   ],
   "source": [
    "# stratefied k fold validation\n",
    "\n",
    "folds = [5, 10, 15]\n",
    "\n",
    "for k in folds:\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100, n_jobs=1) \n",
    "    scores = cross_val_score(model, X, y, cv=skf, n_jobs=-1)\n",
    "    \n",
    "    print(f\"K={k:2d} | Mean Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d7c3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995611109160493\n",
      "F1 Score: 0.8571428571428571\n",
      "Confusion Matrix: [[56862     2]\n",
      " [   23    75]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.97      0.77      0.86        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.88      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reporting of results\n",
    "model_rf = RandomForestClassifier(n_jobs = -1, random_state = 42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_rf)}\")\n",
    "print(f\"Confusion Matrix: {confusion_matrix(y_test, y_pred_rf)}\")\n",
    "print(f\"Classification Report: {classification_report(y_test, y_pred_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71e5b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 5 | Mean Accuracy: 0.9995\n",
      "K=10 | Mean Accuracy: 0.9995\n",
      "K=15 | Mean Accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "# stratefied k fold validation XG Boost\n",
    "folds = [5, 10, 15]\n",
    "for k in folds:\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    model_ = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        tree_method='gpu_hist',\n",
    "        predictor='gpu_predictor', \n",
    "        random_state=42\n",
    "    )\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=skf, n_jobs=1)\n",
    "    print(f\"K={k:2d} | Mean Accuracy: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "786ae0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [19:53:08] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995435553526912\n",
      "F1 Score: 0.8571428571428571\n",
      "Confusion Matrix: [[56858     6]\n",
      " [   20    78]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.93      0.80      0.86        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reporting of results\n",
    "model_xg = XGBClassifier(tree_method = 'hist', predictor = \"gpu_predictor\", random_state = 42)\n",
    "model_xg.fit(X_train, y_train)\n",
    "y_pred_xg = model_xg.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xg)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_xg)}\")\n",
    "print(f\"Confusion Matrix: {confusion_matrix(y_test, y_pred_xg)}\")\n",
    "print(f\"Classification Report: {classification_report(y_test, y_pred_xg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc064526",
   "metadata": {},
   "source": [
    "### Behavior\n",
    "- Accuracy is meaningless due to the class imbalance.\n",
    "- F1 Score balances precision and recall: RF and XGB achieve the same but RF had better precision while XGB had better recall\n",
    "- Recall: XGB had better recall which identified 78/98 frauds while RF got 75/98. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18215130",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d2cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Scores: [0.99947333 0.99934166 0.99945138 0.99947333 0.99918804]\n"
     ]
    }
   ],
   "source": [
    "# 5 fold for all three models\n",
    "skf_5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "tree_model = DecisionTreeClassifier(max_depth=5)\n",
    "tree_scores = cross_val_score(tree_model, X_train, y_train, cv=skf_5)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf_scores = cross_val_score(rf_model, X_train, y_train, cv=skf_5)\n",
    "\n",
    "xgb_model = XGBClassifier(tree_method='hist', n_estimators=100)\n",
    "xgb_scores = cross_val_score(xgb_model, X_train, y_train, cv=skf_5)\n",
    "\n",
    "print(f\"Tree Scores: {tree_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecf5ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[56856     8]\n",
      " [   20    78]]\n",
      "Confusion Matrix: [[56862     2]\n",
      " [   20    78]]\n",
      "Confusion Matrix: [[56858     6]\n",
      " [   20    78]]\n"
     ]
    }
   ],
   "source": [
    "# conf matrices for 5 fold stratefied samples\n",
    "\n",
    "# tree\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "print(f\"Confusion Matrix: {confusion_matrix(y_test, y_pred_tree)}\")\n",
    "\n",
    "# random forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(f\"Confusion Matrix: {confusion_matrix(y_test, y_pred_rf)}\")\n",
    "\n",
    "# xgboost\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xg = xgb_model.predict(X_test)\n",
    "print(f\"Confusion Matrix: {confusion_matrix(y_test, y_pred_xg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add22c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree vs Random Forest:\n",
      "  t-statistic: -4.5984 | p-value: 0.0100\n",
      "  Statistically Significant (p < 0.05): YES\n",
      "Decision Tree vs XGBoost:\n",
      "  t-statistic: 1.0028 | p-value: 0.3727\n",
      "  Statistically Significant (p < 0.05): NO\n",
      "Random Forest vs XGBoost:\n",
      "  t-statistic: 1.0106 | p-value: 0.3694\n",
      "  Statistically Significant (p < 0.05): NO\n"
     ]
    }
   ],
   "source": [
    "# pairs to compare\n",
    "comparisons = [\n",
    "    (\"Decision Tree\", \"Random Forest\", tree_scores, rf_scores),\n",
    "    (\"Decision Tree\", \"XGBoost\", tree_scores, xgb_scores),\n",
    "    (\"Random Forest\", \"XGBoost\", rf_scores, xgb_scores)\n",
    "]\n",
    "\n",
    "for name1, name2, scores1, scores2 in comparisons:\n",
    "    t_stat, p_val = ttest_rel(scores1, scores2)\n",
    "\n",
    "    is_significant = \"YES\" if p_val < 0.05 else \"NO\"\n",
    "    \n",
    "    print(f\"{name1} vs {name2}:\")\n",
    "    print(f\"  t-statistic: {t_stat:.4f} | p-value: {p_val:.4f}\")\n",
    "    print(f\"  Statistically Significant (p < 0.05): {is_significant}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8361978",
   "metadata": {},
   "source": [
    "### Tradeoffs\n",
    "- Decision Tree: high variance + low bias; based on the conf matrix it had the most false positives.\n",
    "- Random Forest: low variance + low bias; stat significantly better than decision tree. targets bias and variance by building parallel trees and aggregating results. \n",
    "- XGBoost: low bias + moderate variance; much faster runtime than the others but not stat sig better than the others. moderate variance due to trying to optimize biases of original tree model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ac660",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
